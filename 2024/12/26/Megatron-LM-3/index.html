<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: light)">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: dark)"><meta name="generator" content="Hexo 6.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/blogs/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/blogs/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/blogs/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/blogs/images/logo.svg" color="#222">

<link rel="stylesheet" href="/blogs/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.6.0/css/all.min.css" integrity="sha256-5eIC48iZUHmSlSUz9XtjRyK2mzQkHScZY1WdMaoz74E=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"zhuogege1943.com","root":"/blogs/","images":"/blogs/images","scheme":"Gemini","darkmode":true,"version":"8.21.1","exturl":false,"sidebar":{"position":"left","width_expanded":320,"width_dual_column":240,"display":"post","padding":18,"offset":12},"hljswrap":true,"copycode":{"enable":false,"style":null},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"duration":200,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"},"path":"/blogs/search.xml","localsearch":{"enable":true,"top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/blogs/js/config.js"></script>

    <meta name="description" content="Reducing Activation Recomputation in Large Transformer Models">
<meta property="og:type" content="article">
<meta property="og:title" content="Megatron-LM (3)">
<meta property="og:url" content="https://zhuogege1943.com/blogs/2024/12/26/Megatron-LM-3/index.html">
<meta property="og:site_name" content="Zhuo&#39;s Blog">
<meta property="og:description" content="Reducing Activation Recomputation in Large Transformer Models">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://zhuogege1943.com/blogs/joplin_resources/3d18b37149176ab5f6bbaa98853201e7.png">
<meta property="og:image" content="https://zhuogege1943.com/blogs/joplin_resources/bc097eaac647dcdf091c8480115856aa.png">
<meta property="og:image" content="https://zhuogege1943.com/blogs/joplin_resources/0ef95fd501438d6f6458d1d8cfab0f92.png">
<meta property="og:image" content="https://zhuogege1943.com/blogs/joplin_resources/198919038772856844e278de52ef0cf8.png">
<meta property="og:image" content="https://zhuogege1943.com/blogs/joplin_resources/ab9adeb4b25f20c6d5ab41737ddd204b.png">
<meta property="og:image" content="https://zhuogege1943.com/blogs/joplin_resources/a480dd0135ebd2f433d33d1c2fd5bfa7.png">
<meta property="og:image" content="https://zhuogege1943.com/blogs/joplin_resources/c544c6ee879141464cc291dbdaf48d0a.png">
<meta property="article:published_time" content="2024-12-26T20:17:01.000Z">
<meta property="article:modified_time" content="2024-12-28T18:32:07.076Z">
<meta property="article:author" content="Zhuo ge ge">
<meta property="article:tag" content="LLM">
<meta property="article:tag" content="Optimization">
<meta property="article:tag" content="Distributed training">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://zhuogege1943.com/blogs/joplin_resources/3d18b37149176ab5f6bbaa98853201e7.png">


<link rel="canonical" href="https://zhuogege1943.com/blogs/2024/12/26/Megatron-LM-3/">


<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"en","comments":true,"permalink":"https://zhuogege1943.com/blogs/2024/12/26/Megatron-LM-3/","path":"2024/12/26/Megatron-LM-3/","title":"Megatron-LM (3)"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>Megatron-LM (3) | Zhuo's Blog</title>
  








  <noscript>
    <link rel="stylesheet" href="/blogs/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/blogs/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">Zhuo's Blog</p>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="Search" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/blogs/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a></li><li class="menu-item menu-item-about"><a href="/blogs/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a></li><li class="menu-item menu-item-tags"><a href="/blogs/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a></li><li class="menu-item menu-item-categories"><a href="/blogs/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a></li><li class="menu-item menu-item-all-blogs"><a href="/blogs/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>All blogs</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
      <div class="search-header">
        <span class="search-icon">
          <i class="fa fa-search"></i>
        </span>
        <div class="search-input-container">
          <input autocomplete="off" autocapitalize="off" maxlength="80"
                placeholder="Searching..." spellcheck="false"
                type="search" class="search-input">
        </div>
        <span class="popup-btn-close" role="button">
          <i class="fa fa-times-circle"></i>
        </span>
      </div>
      <div class="search-result-container">
        <div class="search-result-icon">
          <i class="fa fa-spinner fa-pulse fa-5x"></i>
        </div>
      </div>
    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#Reducing-Activation-Recomputation-in-Large-Transformer-Models"><span class="nav-number">1.</span> <span class="nav-text">Reducing Activation Recomputation in Large Transformer Models</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Contributions"><span class="nav-number">1.1.</span> <span class="nav-text">Contributions</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Methods"><span class="nav-number">1.2.</span> <span class="nav-text">Methods</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Sequence-parallelism"><span class="nav-number">1.2.1.</span> <span class="nav-text">Sequence parallelism</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#Other-notes"><span class="nav-number">1.2.1.1.</span> <span class="nav-text">Other notes</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Selective-Activation-Recomputation"><span class="nav-number">1.2.2.</span> <span class="nav-text">Selective Activation Recomputation</span></a></li></ol></li></ol></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <a href="https://zhuogege1943.com" title=" → personal homepage">
    <img class="site-author-image" itemprop="image" alt="Zhuo ge ge"
      src="/blogs/images/dushen.png">
    </a>
  <p class="site-author-name" itemprop="name">Zhuo ge ge</p>
  <div class="site-description" itemprop="description">Hi, nice to meet you</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/blogs/archives/">
          <span class="site-state-item-count">20</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/blogs/categories/">
        <span class="site-state-item-count">1</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/blogs/tags/">
        <span class="site-state-item-count">11</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <a href="https://github.com/hellozhuo" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;hellozhuo" rel="noopener me" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:zuike2013@outlook.com" title="E-Mail → mailto:zuike2013@outlook.com" rel="noopener me" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="en">
    <link itemprop="mainEntityOfPage" href="https://zhuogege1943.com/blogs/2024/12/26/Megatron-LM-3/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/blogs/images/dushen.png">
      <meta itemprop="name" content="Zhuo ge ge">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhuo's Blog">
      <meta itemprop="description" content="Hi, nice to meet you">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="Megatron-LM (3) | Zhuo's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Megatron-LM (3)
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2024-12-26 22:17:01" itemprop="dateCreated datePublished" datetime="2024-12-26T22:17:01+02:00">2024-12-26</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2024-12-28 20:32:07" itemprop="dateModified" datetime="2024-12-28T20:32:07+02:00">2024-12-28</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/blogs/categories/Paper-reading/" itemprop="url" rel="index"><span itemprop="name">Paper reading</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><h2 id="Reducing-Activation-Recomputation-in-Large-Transformer-Models">Reducing Activation Recomputation in Large Transformer Models</h2>
<span id="more"></span>
<p>paper (2022 arxiv): https://arxiv.org/abs/2205.05198</p>
<h3 id="Contributions">Contributions</h3>
<p>Briefly, the authors based on tensor and pipeline model parallelism, find that the previous parallelism cannot reduce the memory needed for activations while maintaining high device utilization. They propose <span style="color: red;">sequence parallelism</span> and <span style="color: red;">selective activation recomputation</span>.</p>
<h3 id="Methods">Methods</h3>
<h4 id="Sequence-parallelism">Sequence parallelism</h4>
<p>Let’s first analyze the activation memory during training for a single transformer layer without gradient checkpointing (or activation recomputation).</p>
<p><img src="/blogs/joplin_resources/3d18b37149176ab5f6bbaa98853201e7.png" alt=""><br>
<img src="/blogs/joplin_resources/bc097eaac647dcdf091c8480115856aa.png" alt=""><br>
Above is the transformer structure with layer normalizations rearranged in Megatron-LM. Supposing the network and activations are stored in a 16-bit floating point format (2 bytes for each element) and the dropout masks only need 1 byte to store. The activation memory (in bytes) needed for each component is</p>
<ul>
<li>LayerNorm: $4sbh$</li>
<li>Self Attention as follows:<br>
<img src="/blogs/joplin_resources/0ef95fd501438d6f6458d1d8cfab0f92.png" alt=""><br>
Q, K, V: $6sbh$<br>
QK^T + Softmax output: $2s^2b$<br>
Dropout mask: $s^2b$<br>
Dropout output: $2s^2b$<br>
Attention with V: $2sbh$<br>
In total: $8sbh + 5s^2b$</li>
<li>Linear ($h\rightarrow h, h\rightarrow 4h, 4h\rightarrow h$): $2sbh + 8sbh + 2sbh = 12sbh$</li>
<li>Dropout  (masks + output): $1sbh + 2sbh + 1sbh + 2sbh = 6sbh$</li>
<li>GeLU: $8sbh$</li>
</ul>
<p>In total: $34sbh + 5s^2b = sbh(34 + 5\frac{as}{h})$.</p>
<p><img src="/blogs/joplin_resources/198919038772856844e278de52ef0cf8.png" alt=""></p>
<p>However, when applying tensor parallelism (above figure), the output of LayerNorm ($4sbh$), output of dropout layers and dropout masks ($4sbh + 2sbh=6sbh$) are stored in all GPUs. Therefore, $10sbh$ are not parallelized. Therefore, the activations memory per layer is:<br>
$$sbh(10+\frac{24}{t}+5\frac{as}{ht})$$</p>
<p>The authors then propose sequence parallelism to also parallelize these $10sbh$ tensors along their sequency dimension:<br>
<img src="/blogs/joplin_resources/ab9adeb4b25f20c6d5ab41737ddd204b.png" alt=""></p>
<p>To do that, for example, apply sequence parallelism on the two side of MLP tensor parallelism, the method is illustrated as follows:<br>
<img src="/blogs/joplin_resources/a480dd0135ebd2f433d33d1c2fd5bfa7.png" alt=""></p>
<p>Particularly, before the “$g$” function, $Y_1^s, Y_2^s$ are the outputs from the previous sequence parallel stage which are divided along the sequence dimension, therefore, $g$ function uses “all-gather” operator to concatenate them and distribute the result to each tensor parallel device. The outputs of the tensor parallel stage should be processed with “all-reduce” that adds together the outputs and then distributed to each device for the dropout, instead, $\bar g$ uses “reduce-scatter” to scatter (or divide) the reduced results into different segments along the sequence dimension again, each sequence parallel GPU takes one segment for the dropout, followed by another tensor parallel stage.</p>
<p>In this way, all the activations are paralleled. There is no extra communications. Before sequence parallelism, for one forward and backward pass, it needs 4 all-reduce operations. Now, it needs 4 all-gather and 4 reduce-scatter operations, which have the same communication overhead.</p>
<h5 id="Other-notes">Other notes</h5>
<p>The authors also discussed the activations on input and output embeddings, which are negligible compared with the transformer layers.</p>
<h4 id="Selective-Activation-Recomputation">Selective Activation Recomputation</h4>
<p>Generally, we don’t store the softmax output, dropout mask and dropout output which take large amount of memory (the $5\frac{as}{ht}$ term). When doing backward pass, we recompute them based on the stored Q, K, V. However, the calculation of these activations is compute-efficient, so it makes more sense to recompute them.</p>
<p><img src="/blogs/joplin_resources/c544c6ee879141464cc291dbdaf48d0a.png" alt=""></p>
<p>In Table 4, the observation is that the introduction of selective activation recomputation only slightly affects the training speed, while the introduction of sequence parallelism reduce the overhead and speedup training. When two techniques combined, the speed and overhead just slightly affected, but the activation memory per device is significantly reduced (all tensors to $1/t$), which is important for scaling to large models.</p>

    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/blogs/tags/LLM/" rel="tag"># LLM</a>
              <a href="/blogs/tags/Optimization/" rel="tag"># Optimization</a>
              <a href="/blogs/tags/Distributed-training/" rel="tag"># Distributed training</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/blogs/2024/12/26/Megatron-LM-2/" rel="prev" title="Megatron-LM (2)">
                  <i class="fa fa-angle-left"></i> Megatron-LM (2)
                </a>
            </div>
            <div class="post-nav-item">
            </div>
          </div>
    </footer>
  </article>
</div>






    <div class="comments utterances-container"></div>
</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2024</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">Zhuo ge ge</span>
  </div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/" rel="noopener" target="_blank">NexT.Gemini</a>
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="Back to top">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/blogs/js/comments.js"></script><script src="/blogs/js/utils.js"></script><script src="/blogs/js/motion.js"></script><script src="/blogs/js/sidebar.js"></script><script src="/blogs/js/next-boot.js"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous"></script>
<script src="/blogs/js/third-party/search/local-search.js"></script>







  




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"ams","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/blogs/js/third-party/math/mathjax.js"></script>


<script class="next-config" data-name="utterances" type="application/json">{"enable":true,"repo":"hellozhuo/blogs","issue_term":"pathname","theme":"preferred-color-scheme"}</script>
<script src="/blogs/js/third-party/comments/utterances.js"></script>

</body>
</html>
